{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating User Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def signup():\n",
    "    Name=input(\"Name:\")\n",
    "    Email=input(\"Email:\")\n",
    "    Phone=input(\"Phone:\")\n",
    "    Password=input(\"Password:\")\n",
    "    Con_password=input(\"Confirm Password:\")\n",
    "    if Con_password!=Password:\n",
    "        print(\"Passwords don't match. Please Retry\")\n",
    "        signup()\n",
    "    df=pd.read_csv('user_data.csv')\n",
    "    df_2=df[df['email']==Email]\n",
    "    if len(df_2)!=0:\n",
    "        print(\"Email already exists try different email\")\n",
    "        signup()\n",
    "        \n",
    "    wr=open('user_data.csv','a')\n",
    "    wr.write(Name+\",\"+Email+\",\"+Password+\",\"+Phone+\"\\n\")\n",
    "    wr.close()    \n",
    "    print(\"Now please log in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def login():\n",
    "    print(\"1 to Signup, 2 to Login\")\n",
    "    ch=int(input())\n",
    "    if ch==1:\n",
    "        signup()\n",
    "    df=pd.read_csv('user_data.csv')\n",
    "    Email=input(\"Email:\")\n",
    "    Pass=input(\"Pass:\")\n",
    "    \n",
    "    df_2=df[df['email']==Email]\n",
    "    #print(df_2)\n",
    "    \n",
    "    if len(df_2)==0:\n",
    "        print(\"Email not found, try again\")\n",
    "        login()\n",
    "    \n",
    "    if str(df_2.iloc[0]['password'])==Pass:\n",
    "        print(\"Welcome \"+df.iloc[0]['Name'])\n",
    "        surf(Email)\n",
    "        \n",
    "    else:\n",
    "        print(\"Password Wrong, try again\")\n",
    "        login()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining the stories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import system, name \n",
    "def clear(): \n",
    "  \n",
    "    # for windows \n",
    "    if name == 'nt': \n",
    "        _ = system('cls') \n",
    "  \n",
    "    # for mac and linux(here, os.name is 'posix') \n",
    "    else: \n",
    "        _ = system('clear') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "def get_stories():\n",
    "    fldr='feeds'\n",
    "    files=os.listdir(fldr)\n",
    "    df_f=pd.DataFrame()\n",
    "    \n",
    "    for i in files:\n",
    "        fl=fldr+'/'+i\n",
    "        \n",
    "        df=pd.read_csv(fl)\n",
    "        if df_f is None:\n",
    "            df_f=df\n",
    "        else:\n",
    "            df_f=pd.concat([df_f,df],axis=0)\n",
    "    \n",
    "    return df_f\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "def clean_sentence(sentence):\n",
    "    #extracts=sent_tokenize(article)\n",
    "    sentences=[]\n",
    "  \n",
    "    #print(extract)\n",
    "    clean_sentence=sentence.replace(\"[^a-zA-Z0-9]\",\" \")   ## Removing special characters\n",
    "    #print(clean_sentence)\n",
    "    obtained=word_tokenize(clean_sentence) \n",
    "    #print(obtained)\n",
    "    sentences.append(obtained)\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/abhijit/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/abhijit/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.cluster.util import cosine_distance\n",
    "def get_similarity(sent_1,sent_2,stop_words):\n",
    "  \n",
    "  sent_1=[w.lower() for w in sent_1]\n",
    "  sent_2=[w.lower() for w in sent_2]\n",
    "\n",
    "  total=list(set(sent_1+sent_2)) ## Removing duplicate words in total set\n",
    "\n",
    "  vec_1= [0] * len(total)\n",
    "  vec_2= [0] * len(total)\n",
    "\n",
    "\n",
    "  ## Count Vectorization of two sentences\n",
    "  for w in sent_1:\n",
    "    if w not in stop_words:\n",
    "      vec_1[total.index(w)]+=1\n",
    "\n",
    "  for w in sent_2:\n",
    "    if w not in stop_words:\n",
    "      vec_2[total.index(w)]+=1\n",
    "\n",
    "\n",
    "  return 1-cosine_distance(vec_1,vec_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/abhijit/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "def handle_similar(df, Title,email):\n",
    "    clear()\n",
    "    sim=[]\n",
    "    df_temp=df\n",
    "    print(\"\\n\\n Here are some similar Stories \\n\\n\")\n",
    "    for i in range(len(df)):\n",
    "        try:\n",
    "            title=ast.literal_eval(df.iloc[i]['Titles'])[0]\n",
    "            cleaned_1=clean_sentence(Title)\n",
    "            cleaned_2=clean_sentence(title)\n",
    "            stop_words = stopwords.words('english')\n",
    "            s=get_similarity(cleaned_1,cleaned_2,stop_words)\n",
    "            if s<0.95:\n",
    "                sim.append(s)\n",
    "            else:\n",
    "                sim.append(0)\n",
    "        except:\n",
    "            sim.append(0)\n",
    "        \n",
    "    df_temp['Sim']=sim\n",
    "        \n",
    "    df_temp.sort_values(by=['Sim'], inplace=True,ascending=False)\n",
    "    #print(df_temp['Sim'].head())    \n",
    "        \n",
    "    for i in range(5):\n",
    "        try:\n",
    "            res = ast.literal_eval(df_temp.iloc[i]['Titles']) \n",
    "            print(str(i+1)+\"-> \"+res[0])\n",
    "            print(df_temp.iloc[i]['Source']+\", Today\")\n",
    "        \n",
    "            print('\\n\\n')\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "    print(\"1 for choosing proposed, 2 to go back\")\n",
    "    choice=int(input())\n",
    "    if choice==2:\n",
    "        surf(email)\n",
    "    else:\n",
    "        try:\n",
    "            ind=int(input(\"Please Provide the index of the story\"))\n",
    "            webbrowser.open(df_temp.iloc[ind-1]['link'])\n",
    "            time.sleep(3)\n",
    "\n",
    "            file_u = open('user_records.json')\n",
    "            users=json.load(file_u)\n",
    "\n",
    "            if email not in users.keys():\n",
    "                users[email]={}\n",
    "                \n",
    "                users[email]['news']=[df_temp[ind-1]['Source']+df_temp.iloc[ind-1]['Date']+ast.literal_eval(df_temp.iloc[ind-1]['Titles'])[0]]\n",
    "                lab=[z for z in ast.literal_eval(df_temp.iloc[ind-1]['labels'])]\n",
    "                users[email]['labels']=lab\n",
    "            else:\n",
    "                users[email]['news'].append(df_temp.iloc[ind-1]['Source']+df_temp.iloc[ind-1]['Date']+ast.literal_eval(df_temp.iloc[ind-1]['Titles'])[0])\n",
    "                lab=[z for z in ast.literal_eval(df_temp.iloc[ind-1]['labels'])]\n",
    "                for l in lab:\n",
    "                    users[email]['labels'].append(l)\n",
    "            with open(\"user_records.json\", \"w\") as outfile: \n",
    "                json.dump(users, outfile)\n",
    "\n",
    "            file_s = open('story_records.json')\n",
    "            stories=json.load(file_s)\n",
    "            key=df_temp.iloc[ind-1]['Source']+'$'+df_temp.iloc[ind-1]['Date']+'$'+ast.literal_eval(df_temp.iloc[ind-1]['Titles'])[0]\n",
    "\n",
    "            if key not in stories.keys():\n",
    "\n",
    "                stories[key]=[email]\n",
    "            else:\n",
    "                stories[key].append(email)\n",
    "\n",
    "            with open(\"story_records.json\", \"w\") as outfile: \n",
    "                json.dump(stories, outfile) \n",
    "        except:\n",
    "            a=1\n",
    "        handle_similar(df,ast.literal_eval(df_temp.iloc[ind-1]['Titles'])[0],email)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(email,df):\n",
    "    clear()\n",
    "    search=input(\"search\")\n",
    "    df_temp=df\n",
    "    sim=[]\n",
    "    for i in range(len(df)):\n",
    "        try:\n",
    "            title=ast.literal_eval(df.iloc[i]['Titles'])[0]\n",
    "            cleaned_1=clean_sentence(search)\n",
    "            cleaned_2=clean_sentence(title)\n",
    "            stop_words = stopwords.words('english')\n",
    "            s=get_similarity(cleaned_1,cleaned_2,stop_words)\n",
    "            if s<0.95:\n",
    "                sim.append(s)\n",
    "            else:\n",
    "                sim.append(0)\n",
    "        except:\n",
    "            sim.append(0)\n",
    "            \n",
    "    df_temp['Sim']=sim\n",
    "    df_temp.sort_values(by=['Sim'], inplace=True,ascending=False)\n",
    "    #print(df_temp.head())\n",
    "    print(\"\\n\\n Top 5 Results \\n\")\n",
    "    for i in range(5):\n",
    "        \n",
    "            res = ast.literal_eval(df_temp.iloc[i]['Titles']) \n",
    "            print(str(i+1)+\"-> \"+res[0])\n",
    "            print(df_temp.iloc[i]['Source']+\" , \"+df_temp.iloc[i]['Date'])\n",
    "        \n",
    "            print('\\n\\n')\n",
    "        \n",
    "    ind=int(input(\"Please Provide the index of the story\"))\n",
    "        #print(str(stories_checked.iloc[indices[ind-1]]['link']))\n",
    "    \n",
    "            #ind=int(input(\"Please Provide the index of the story\"))\n",
    "    webbrowser.open(df_temp.iloc[ind-1]['link'])\n",
    "    time.sleep(3)\n",
    "    \n",
    "    try:\n",
    "    \n",
    "            file_u = open('user_records.json')\n",
    "            users=json.load(file_u)\n",
    "\n",
    "            if email not in users.keys():\n",
    "                users[email]={}\n",
    "                \n",
    "                users[email]['news']=[df_temp[ind-1]['Source']+df_temp.iloc[ind-1]['Date']+ast.literal_eval(df_temp.iloc[ind-1]['Titles'])[0]]\n",
    "                lab=[z for z in ast.literal_eval(df_temp.iloc[ind-1]['labels'])]\n",
    "                users[email]['labels']=lab\n",
    "            else:\n",
    "                users[email]['news'].append(df_temp.iloc[ind-1]['Source']+df_temp.iloc[ind-1]['Date']+ast.literal_eval(df_temp.iloc[ind-1]['Titles'])[0])\n",
    "                lab=[z for z in ast.literal_eval(df_temp.iloc[ind-1]['labels'])]\n",
    "                for l in lab:\n",
    "                    users[email]['labels'].append(l)\n",
    "        \n",
    "            with open(\"user_records.json\", \"w\") as outfile: \n",
    "                json.dump(users, outfile)\n",
    "    \n",
    "            file_s = open('story_records.json')\n",
    "            stories=json.load(file_s)\n",
    "            key=df_temp.iloc[ind-1]['Source']+'$'+df_temp.iloc[ind-1]['Date']+'$'+ast.literal_eval(df_temp.iloc[ind-1]['Titles'])[0]\n",
    "\n",
    "            if key not in stories.keys():\n",
    "\n",
    "                stories[key]=[email]\n",
    "            else:\n",
    "                stories[key].append(email)\n",
    "\n",
    "            with open(\"story_records.json\", \"w\") as outfile: \n",
    "                json.dump(stories, outfile) \n",
    "    except:\n",
    "    \n",
    "            a=1\n",
    "    surf(email)\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def get_popular(email,df):\n",
    "    clear()\n",
    "    #print(\"A\")\n",
    "    df_temp=df\n",
    "    file_u = open('user_records.json')\n",
    "    users=json.load(file_u)\n",
    "    file_s = open('story_records.json')\n",
    "    stories=json.load(file_s)\n",
    "    \n",
    "    popularity=[]\n",
    "    for i in range(len(df)):\n",
    "        try:\n",
    "            key=df.iloc[i]['Source']+'$'+df.iloc[i]['Date']+'$'+ast.literal_eval(df_temp.iloc[i]['Titles'])[0]\n",
    "            if key in stories.keys():\n",
    "                p=stories.get(key)\n",
    "                if email in p:\n",
    "                    popularity.append(0)\n",
    "                else:\n",
    "                    popularity.append(len(p))\n",
    "            else:\n",
    "                popularity.append(0)\n",
    "        except:\n",
    "            popularity.append(0)\n",
    "    \n",
    "    df_temp['Pop']=popularity \n",
    "    df_temp.sort_values(by=['Pop'], inplace=True,ascending=False)\n",
    "    print(\"\\n\\n Top 10 Results \\n\")\n",
    "    for i in range(10):\n",
    "        try:\n",
    "            res = ast.literal_eval(df_temp.iloc[i]['Titles']) \n",
    "            print(str(i+1)+\"-> \"+res[0])\n",
    "            print(df_temp.iloc[i]['Source']+\" , \"+df_temp.iloc[i]['Date'])\n",
    "        \n",
    "            print('\\n\\n')\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "    ind=int(input(\"Please Provide the index of the story\"))\n",
    "        #print(str(stories_checked.iloc[indices[ind-1]]['link']))\n",
    "    \n",
    "            #ind=int(input(\"Please Provide the index of the story\"))\n",
    "    webbrowser.open(df_temp.iloc[ind-1]['link'])\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "            file_u = open('user_records.json')\n",
    "            users=json.load(file_u)\n",
    "\n",
    "            if email not in users.keys():\n",
    "                users[email]={}\n",
    "                \n",
    "                users[email]['news']=[df_temp[ind-1]['Source']+df_temp.iloc[ind-1]['Date']+ast.literal_eval(df_temp.iloc[ind-1]['Titles'])[0]]\n",
    "                lab=[z for z in ast.literal_eval(df_temp.iloc[ind-1]['labels'])]\n",
    "                users[email]['labels']=lab\n",
    "            else:\n",
    "                users[email]['news'].append(df_temp.iloc[ind-1]['Source']+df_temp.iloc[ind-1]['Date']+ast.literal_eval(df_temp.iloc[ind-1]['Titles'])[0])\n",
    "                lab=[z for z in ast.literal_eval(df_temp.iloc[ind-1]['labels'])]\n",
    "                for l in lab:\n",
    "                    users[email]['labels'].append(l)\n",
    "                \n",
    "            with open(\"user_records.json\", \"w\") as outfile: \n",
    "                json.dump(users, outfile)\n",
    "\n",
    "            file_s = open('story_records.json')\n",
    "            stories=json.load(file_s)\n",
    "            key=df_temp.iloc[ind-1]['Source']+'$'+df_temp.iloc[ind-1]['Date']+'$'+ast.literal_eval(df_temp.iloc[ind-1]['Titles'])[0]\n",
    "\n",
    "            if key not in stories.keys():\n",
    "\n",
    "                stories[key]=[email]\n",
    "            else:\n",
    "                stories[key].append(email)\n",
    "\n",
    "            with open(\"story_records.json\", \"w\") as outfile: \n",
    "                json.dump(stories, outfile) \n",
    "    except:\n",
    "            a=1\n",
    "    surf(email)\n",
    "\n",
    "    \n",
    "    \n",
    "            \n",
    "        \n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content Based Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def get_customized(email,df):\n",
    "    clear()\n",
    "    file_u = open('user_records.json')\n",
    "    users=json.load(file_u)\n",
    "    \n",
    "    file_s = open('story_records.json')\n",
    "    stories=json.load(file_s)\n",
    "        \n",
    "    df_temp=df\n",
    "    \n",
    "    sim=[]\n",
    "    \n",
    "    if email in users.keys():\n",
    "        tag_usr=\"\"\n",
    "        temp=users.get(email)\n",
    "        temp=temp.get('labels')\n",
    "        i= len(temp)-1\n",
    "        count=0\n",
    "        while i>=0:\n",
    "            if count==20:\n",
    "                break\n",
    "            tag_usr+=temp[i]+\" \"\n",
    "            i-=1\n",
    "            count+=1\n",
    "        #print(tag_usr)\n",
    "        for i in range(len(df)):\n",
    "            try:\n",
    "                key=df.iloc[i]['Source']+'$'+df.iloc[i]['Date']+'$'+ast.literal_eval(df_temp.iloc[i]['Titles'])[0]\n",
    "                if key in stories.keys():\n",
    "                    p=stories.get(key)\n",
    "                    if email in p:\n",
    "                        sim.append(0)\n",
    "                    else:\n",
    "                        tag_str=\"\"\n",
    "                        lab=ast.literal_eval(df_temp.iloc[i][\"labels\"])\n",
    "                        for l in lab:\n",
    "                            tag_str+=l+\" \"\n",
    "                        cleaned_1=clean_sentence(tag_usr)\n",
    "                        cleaned_2=clean_sentence(tag_str)\n",
    "                        s=get_similarity(cleaned_1,cleaned_2)\n",
    "                        sim.append(s)\n",
    "                        \n",
    "                        \n",
    "                else:\n",
    "                    sim.append(0)\n",
    "            except:\n",
    "                sim.append(0)\n",
    "        df_temp['sim']=sim \n",
    "        df_temp.sort_values(by=['sim'], inplace=True,ascending=False)\n",
    "        print(\"\\n\\n Top 10 Results \\n\")\n",
    "        for i in range(10):\n",
    "            try:\n",
    "                res = ast.literal_eval(df_temp.iloc[i]['Titles']) \n",
    "                print(str(i+1)+\"-> \"+res[0])\n",
    "                print(df_temp.iloc[i]['Source']+\" , \"+df_temp.iloc[i]['Date'])\n",
    "        \n",
    "                print('\\n\\n')\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        ind=int(input(\"Please Provide the index of the story\"))\n",
    "            #print(str(stories_checked.iloc[indices[ind-1]]['link']))\n",
    "    \n",
    "            #ind=int(input(\"Please Provide the index of the story\"))\n",
    "        webbrowser.open(df_temp.iloc[ind-1]['link'])\n",
    "        time.sleep(3)\n",
    "        try:\n",
    "                file_u = open('user_records.json')\n",
    "                users=json.load(file_u)\n",
    "\n",
    "                if email not in users.keys():\n",
    "                    users[email]={}\n",
    "                \n",
    "                    users[email]['news']=[df_temp[ind-1]['Source']+df_temp.iloc[ind-1]['Date']+ast.literal_eval(df_temp.iloc[ind-1]['Titles'])[0]]\n",
    "                    lab=[z for z in ast.literal_eval(df_temp.iloc[ind-1]['labels'])]\n",
    "                    users[email]['labels']=lab\n",
    "                else:\n",
    "                    users[email]['news'].append(df_temp.iloc[ind-1]['Source']+df_temp.iloc[ind-1]['Date']+ast.literal_eval(df_temp.iloc[ind-1]['Titles'])[0])\n",
    "                    lab=[z for z in ast.literal_eval(df_temp.iloc[ind-1]['labels'])]\n",
    "                    for l in lab:\n",
    "                        users[email]['labels'].append(l)\n",
    "                \n",
    "                with open(\"user_records.json\", \"w\") as outfile: \n",
    "                    json.dump(users, outfile)\n",
    "\n",
    "                file_s = open('story_records.json')\n",
    "                stories=json.load(file_s)\n",
    "                key=df_temp.iloc[ind-1]['Source']+'$'+df_temp.iloc[ind-1]['Date']+'$'+ast.literal_eval(df_temp.iloc[ind-1]['Titles'])[0]\n",
    "\n",
    "                if key not in stories.keys():\n",
    "\n",
    "                    stories[key]=[email]\n",
    "                else:\n",
    "                    stories[key].append(email)\n",
    "\n",
    "                with open(\"story_records.json\", \"w\") as outfile: \n",
    "                    json.dump(stories, outfile) \n",
    "        except:\n",
    "                a=1\n",
    "        handle_similar(df,ast.literal_eval(df_temp.iloc[ind-1]['Titles'])[0],email)\n",
    "         \n",
    "    else:\n",
    "        get_popular(email,df)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime \n",
    "import random\n",
    "import ast,time\n",
    "import webbrowser\n",
    "import json\n",
    "def surf(email):\n",
    "    clear()\n",
    "    date=datetime.today().strftime('%Y-%m-%d')\n",
    "    \n",
    "    stories=get_stories()\n",
    "    \n",
    "    stories_checked=stories[stories[\"Date\"]==date]\n",
    "    length=len(stories_checked)\n",
    "    print()\n",
    "    indices=[]\n",
    "    \n",
    "    for _ in range(8):\n",
    "        indices.append(random.randint(0,length))\n",
    "    \n",
    "    print(\"LATEST FEED: \\n\\n\")\n",
    "    \n",
    "    for i in range(len(indices)-1):\n",
    "        try:\n",
    "            #print(indices[i])\n",
    "            res = ast.literal_eval(stories_checked.iloc[indices[i]]['Titles']) \n",
    "            print(str(i+1)+\"-> \"+res[0])\n",
    "            print(stories_checked.iloc[indices[i]]['Source']+\", Today\")\n",
    "        \n",
    "            print('\\n\\n')\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "    print('1 for searching, 2 for reading from feed, 3 for popular stories, 4 for customized stories, 5 to quit')\n",
    "    \n",
    "    choice=int(input())\n",
    "    if choice==2:\n",
    "        \n",
    "            ind=int(input(\"Please Provide the index of the story\"))\n",
    "            #print(str(stories_checked.iloc[indices[ind-1]]['link']))\n",
    "            webbrowser.open(str(stories_checked.iloc[indices[ind-1]]['link']))\n",
    "            time.sleep(3)\n",
    "        \n",
    "            file_u = open('user_records.json')\n",
    "            users=json.load(file_u)\n",
    "\n",
    "            if email not in users.keys():\n",
    "                users[email]={}\n",
    "                \n",
    "                users[email]['news']=[stories_checked.iloc[indices[ind-1]]['Source']+stories_checked.iloc[indices[ind-1]]['Date']+ast.literal_eval(stories_checked.iloc[indices[ind-1]]['Titles'])[0]]\n",
    "                lab=[z for z in ast.literal_eval(stories_checked.iloc[indices[ind-1]]['labels'])]\n",
    "                users[email]['labels']=lab\n",
    "            else:\n",
    "                users[email]['news'].append(stories_checked.iloc[indices[ind-1]]['Source']+stories_checked.iloc[indices[ind-1]]['Date']+ast.literal_eval(stories_checked.iloc[indices[ind-1]]['Titles'])[0])\n",
    "                lab=[z for z in ast.literal_eval(stories_checked.iloc[indices[ind-1]]['labels'])]\n",
    "                for l in lab:\n",
    "                    users[email]['labels'].append(l)\n",
    "            #json.dump(users,'user_records.json')\n",
    "            #print(users)\n",
    "            \n",
    "            with open(\"user_records.json\", \"w\") as outfile: \n",
    "                json.dump(users, outfile) \n",
    "\n",
    "            file_s = open('story_records.json')\n",
    "            stories=json.load(file_s)\n",
    "            key=stories_checked.iloc[indices[ind-1]]['Source']+'$'+stories_checked.iloc[indices[ind-1]]['Date']+'$'+ast.literal_eval(stories_checked.iloc[indices[ind-1]]['Titles'])[0]\n",
    "\n",
    "            if key not in stories.keys():\n",
    "\n",
    "                stories[key]=[email]\n",
    "            else:\n",
    "                stories[key].append(email)\n",
    "            with open(\"story_records.json\", \"w\") as outfile: \n",
    "                json.dump(stories, outfile) \n",
    "\n",
    "            a=1\n",
    "        #json.dump(stories,'story_records.json')\n",
    "        \n",
    "        \n",
    "            handle_similar(stories_checked,ast.literal_eval(stories_checked.iloc[indices[ind-1]]['Titles'])[0],email)\n",
    "    elif choice==1:\n",
    "        search(email,stories)\n",
    "    \n",
    "    elif choice==3:\n",
    "        get_popular(email,stories)\n",
    "    \n",
    "    elif choice==4:\n",
    "        get_customized(email,stories)\n",
    "        \n",
    "    elif choice==5:\n",
    "        print(\"BYE\")\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 to Signup, 2 to Login\n",
      "2\n",
      "Email:XYZ@gmail.com\n",
      "Pass:1234\n",
      "Welcome XYZ\n",
      "\n",
      "LATEST FEED: \n",
      "\n",
      "\n",
      "1-> With single-day spike of 75,809 cases and record 1,133 deaths, India's COVID-19 tally nears 43 lakh mark\n",
      "Times_Now, Today\n",
      "\n",
      "\n",
      "\n",
      "2->  Sikhs to be counted as a separate ethnic group in 2020 US census for first time\n",
      "IndiaToday, Today\n",
      "\n",
      "\n",
      "\n",
      "3->  IMPACT FEATURE Campus placements go virtual as universities adapt\n",
      "IndiaToday, Today\n",
      "\n",
      "\n",
      "\n",
      "4-> Delhi BJP Stages Protest, Says AAP Govt Should Release Funds Of Municipal Corporations\n",
      "Republic TV, Today\n",
      "\n",
      "\n",
      "\n",
      "5-> Kerala gold smuggling case: Swapna Suresh shifted to ICU after complaining of chest pain\n",
      "Times_Now, Today\n",
      "\n",
      "\n",
      "\n",
      "6->  Govt orders clinical study into Covid-19 re-infection after Bengaluru case\n",
      "IndiaToday, Today\n",
      "\n",
      "\n",
      "\n",
      "7-> Subramanian Swamy Questions EAM Jaishankar's Scheduled Meeting With Chinese FM In Moscow\n",
      "Republic TV, Today\n",
      "\n",
      "\n",
      "\n",
      "1 for searching, 2 for reading from feed, 3 for popular stories, 4 for customized stories, 5 to quit\n",
      "2\n",
      "Please Provide the index of the story4\n",
      "\n",
      "\n",
      " Here are some similar Stories \n",
      "\n",
      "\n",
      "1-> MS Dhoni leaves Irfan Pathan surprised, does wicket-keeping drills in CSK training ahead of IPL 2020\n",
      "Times_Now, Today\n",
      "\n",
      "\n",
      "\n",
      "2-> COVID-19 Menace Can Only Be Tackled With Active Support Of People: Rajasthan Health Minister\n",
      "Republic TV, Today\n",
      "\n",
      "\n",
      "\n",
      "3->     Sushant Singh Rajput case LIVE updates: NCB summons Rhea 3rd time\n",
      "IndiaToday, Today\n",
      "\n",
      "\n",
      "\n",
      "4-> BJP and Shiv Sena lock horns over election of deputy chairman\n",
      "Times_Now, Today\n",
      "\n",
      "\n",
      "\n",
      "5-> Mumbai PoK row: Shiv Sena IT cell files complaint against Kangana Ranaut seeking FIR under sedition charge\n",
      "Times_Now, Today\n",
      "\n",
      "\n",
      "\n",
      "1 for choosing proposed, 2 to go back\n",
      "2\n",
      "\n",
      "LATEST FEED: \n",
      "\n",
      "\n",
      "1-> 6 Workers Fall Sick After Gas Leak From Factory In Maharashtra\n",
      "Republic TV, Today\n",
      "\n",
      "\n",
      "\n",
      "2-> First batch of Russian coronavirus vaccine released into public\n",
      "Times_Now, Today\n",
      "\n",
      "\n",
      "\n",
      "3-> Delhi BJP Stages Protest, Says AAP Govt Should Release Funds Of Municipal Corporations\n",
      "Republic TV, Today\n",
      "\n",
      "\n",
      "\n",
      "4-> No firing happened: India denies Chinese claims of 'fired threats' by Indian Army troops south of Pangong Tso\n",
      "Times_Now, Today\n",
      "\n",
      "\n",
      "\n",
      "5-> Kamala Harris will never be president, says Trump, slams Democrats’ for ‘reckless anti-vaccine rhetoric’\n",
      "Times_Now, Today\n",
      "\n",
      "\n",
      "\n",
      "6-> Controlled, Not Crushed: Jaish-e-Muhammad Asks Pakistan to Lift Restrictions on Attacks in Kashmir\n",
      "News18, Today\n",
      "\n",
      "\n",
      "\n",
      "7-> China acted in an open and transparent manner on coronavirus outbreak, says President Xi Jinping\n",
      "Times_Now, Today\n",
      "\n",
      "\n",
      "\n",
      "1 for searching, 2 for reading from feed, 3 for popular stories, 4 for customized stories, 5 to quit\n",
      "5\n",
      "BYE\n"
     ]
    }
   ],
   "source": [
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 to Signup, 2 to Login\n",
      "2\n",
      "Email:XYZ@gmail.com\n",
      "Pass:1234\n",
      "Welcome XYZ\n",
      "\n",
      "LATEST FEED: \n",
      "\n",
      "\n",
      "1 for searching, 2 for reading from feed, 3 for popular stories, 4 for customized stories, 5 to quit\n",
      "4\n",
      "\n",
      "\n",
      " Top 10 Results \n",
      "\n",
      "1-> With single-day spike of 75,809 cases and record 1,133 deaths, India's COVID-19 tally nears 43 lakh mark\n",
      "Times_Now , 2020-09-08\n",
      "\n",
      "\n",
      "\n",
      "2-> Rhea Chakraborty admits to Narcotics Control Bureau she was procuring drugs 'but never consumed them'\n",
      "Times_Now , 2020-09-06\n",
      "\n",
      "\n",
      "\n",
      "3-> Kerala Trumps States in Literacy Rate, Delhi Emerges 2nd Best; Andhra Ranks Worst\n",
      "News18 , 2020-09-07\n",
      "\n",
      "\n",
      "\n",
      "4-> India Didn't Prioritise Mental Health Before Covid-19. Now it's Paying the Price\n",
      "News18 , 2020-09-07\n",
      "\n",
      "\n",
      "\n",
      "5-> Sandip Ssingh Shares Chats With Sushant, Sister Mitu Singh: My Silence Broke 20 Years of My Image\n",
      "News18 , 2020-09-07\n",
      "\n",
      "\n",
      "\n",
      "6-> Cristiano Ronaldo Forgot to Wear a Face Mask in the Stands, But Proved He's Not a Covidiot\n",
      "News18 , 2020-09-07\n",
      "\n",
      "\n",
      "\n",
      "7-> Vodafone-Idea to Make Major Announcement at 11:45AM Today; Amazon, Verizon Investment in Sight?\n",
      "News18 , 2020-09-07\n",
      "\n",
      "\n",
      "\n",
      "8-> Novak Djokovic 'Defaulted' Out of US Open After Striking Line Judge in Throat with Ball\n",
      "News18 , 2020-09-07\n",
      "\n",
      "\n",
      "\n",
      "9-> India Could Clock More Than $100 Billion In Mobile Phone Exports As Apple And Samsung Lead The Way\n",
      "News18 , 2020-09-07\n",
      "\n",
      "\n",
      "\n",
      "10-> Security tightened at Uddhav Thackeray’s residence as Maharashtra CM gets calls ‘on behalf of Dawood Ibrahim’\n",
      "Times_Now , 2020-09-06\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    877\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    879\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    466\u001b[0m         \"\"\"\n\u001b[0;32m--> 467\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-342-390877b5064f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlogin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-238-426f0734b2c7>\u001b[0m in \u001b[0;36mlogin\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'password'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mPass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Welcome \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0msurf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmail\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-337-6a70cdd53c19>\u001b[0m in \u001b[0;36msurf\u001b[0;34m(email)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mchoice\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mget_customized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memail\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mchoice\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-334-594259d1fe21>\u001b[0m in \u001b[0;36mget_customized\u001b[0;34m(email, df)\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Please Provide the index of the story\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0;31m#print(str(stories_checked.iloc[indices[ind-1]]['link']))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    851\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m         )\n\u001b[1;32m    855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    884\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
