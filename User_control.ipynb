{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating User Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def signup():\n",
    "    Name=input(\"Name:\")\n",
    "    Email=input(\"Email:\")\n",
    "    Phone=input(\"Phone:\")\n",
    "    Password=input(\"Password:\")\n",
    "    Con_password=input(\"Confirm Password:\")\n",
    "    if Con_password!=Password:\n",
    "        print(\"Passwords don't match. Please Retry\")\n",
    "        signup()\n",
    "    df=pd.read_csv('user_data.csv')\n",
    "    df_2=df[df['email']==Email]\n",
    "    if len(df_2)!=0:\n",
    "        print(\"Email already exists try different email\")\n",
    "        signup()\n",
    "        \n",
    "    wr=open('user_data.csv','a')\n",
    "    wr.write(Name+\",\"+Email+\",\"+Password+\",\"+Phone+\"\\n\")\n",
    "    wr.close()    \n",
    "    print(\"Now please log in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def login():\n",
    "    print(\"1 to Signup, 2 to Login\")\n",
    "    ch=int(input())\n",
    "    if ch==1:\n",
    "        signup()\n",
    "    df=pd.read_csv('user_data.csv')\n",
    "    Email=input(\"Email:\")\n",
    "    Pass=input(\"Pass:\")\n",
    "    \n",
    "    df_2=df[df['email']==Email]\n",
    "    #print(df_2)\n",
    "    \n",
    "    if len(df_2)==0:\n",
    "        print(\"Email not found, try again\")\n",
    "        login()\n",
    "    \n",
    "    if str(df_2.iloc[0]['password'])==Pass:\n",
    "        print(\"Welcome \"+df.iloc[0]['Name'])\n",
    "        surf(Email)\n",
    "        \n",
    "    else:\n",
    "        print(\"Password Wrong, try again\")\n",
    "        login()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining the stories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import system, name \n",
    "def clear(): \n",
    "  \n",
    "    # for windows \n",
    "    if name == 'nt': \n",
    "        _ = system('cls') \n",
    "  \n",
    "    # for mac and linux(here, os.name is 'posix') \n",
    "    else: \n",
    "        _ = system('clear') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "def get_stories():\n",
    "    fldr='feeds'\n",
    "    files=os.listdir(fldr)\n",
    "    df_f=pd.DataFrame()\n",
    "    \n",
    "    for i in files:\n",
    "        fl=fldr+'/'+i\n",
    "        \n",
    "        df=pd.read_csv(fl)\n",
    "        if df_f is None:\n",
    "            df_f=df\n",
    "        else:\n",
    "            df_f=pd.concat([df_f,df],axis=0)\n",
    "    \n",
    "    return df_f\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "def clean_sentence(sentence):\n",
    "    #extracts=sent_tokenize(article)\n",
    "    sentences=[]\n",
    "  \n",
    "    #print(extract)\n",
    "    clean_sentence=sentence.replace(\"[^a-zA-Z0-9]\",\" \")   ## Removing special characters\n",
    "    #print(clean_sentence)\n",
    "    obtained=word_tokenize(clean_sentence) \n",
    "    #print(obtained)\n",
    "    sentences.append(obtained)\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/abhijit/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/abhijit/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.cluster.util import cosine_distance\n",
    "def get_similarity(sent_1,sent_2,stop_words):\n",
    "  \n",
    "  sent_1=[w.lower() for w in sent_1]\n",
    "  sent_2=[w.lower() for w in sent_2]\n",
    "\n",
    "  total=list(set(sent_1+sent_2)) ## Removing duplicate words in total set\n",
    "\n",
    "  vec_1= [0] * len(total)\n",
    "  vec_2= [0] * len(total)\n",
    "\n",
    "\n",
    "  ## Count Vectorization of two sentences\n",
    "  for w in sent_1:\n",
    "    if w not in stop_words:\n",
    "      vec_1[total.index(w)]+=1\n",
    "\n",
    "  for w in sent_2:\n",
    "    if w not in stop_words:\n",
    "      vec_2[total.index(w)]+=1\n",
    "\n",
    "\n",
    "  return 1-cosine_distance(vec_1,vec_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/abhijit/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "def handle_similar(df, Title,email):\n",
    "    clear()\n",
    "    sim=[]\n",
    "    df_temp=df\n",
    "    print(\"\\n\\n Here are some similar Stories \\n\\n\")\n",
    "    for i in range(len(df)):\n",
    "        try:\n",
    "            title=ast.literal_eval(df.iloc[i]['Titles'])[0]\n",
    "            cleaned_1=clean_sentence(Title)\n",
    "            cleaned_2=clean_sentence(title)\n",
    "            stop_words = stopwords.words('english')\n",
    "            s=get_similarity(cleaned_1,cleaned_2,stop_words)\n",
    "            if s<0.95:\n",
    "                sim.append(s)\n",
    "            else:\n",
    "                sim.append(0)\n",
    "        except:\n",
    "            sim.append(0)\n",
    "        \n",
    "    df_temp['Sim']=sim\n",
    "        \n",
    "    df_temp.sort_values(by=['Sim'], inplace=True,ascending=False)\n",
    "    #print(df_temp['Sim'].head())    \n",
    "        \n",
    "    for i in range(5):\n",
    "        try:\n",
    "            res = ast.literal_eval(df_temp.iloc[i]['Titles']) \n",
    "            print(str(i+1)+\"-> \"+res[0])\n",
    "            print(df_temp.iloc[i]['Source']+\", Today\")\n",
    "        \n",
    "            print('\\n\\n')\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "    print(\"1 for choosing proposed, 2 to go back\")\n",
    "    choice=int(input())\n",
    "    if choice==2:\n",
    "        surf(email)\n",
    "    else:\n",
    "        try:\n",
    "            ind=int(input(\"Please Provide the index of the story\"))\n",
    "            webbrowser.open(df_temp.iloc[ind-1]['link'])\n",
    "            time.sleep(3)\n",
    "\n",
    "            file_u = open('user_records.json')\n",
    "            users=json.load(file_u)\n",
    "\n",
    "            if email not in users.keys():\n",
    "                users[email]={}\n",
    "                \n",
    "                users[email]['news']=[df_temp[ind-1]['Source']+df_temp.iloc[ind-1]['Date']+ast.literal_eval(df_temp.iloc[ind-1]['Titles'])[0]]\n",
    "                lab=[z for z in ast.literal_eval(df_temp.iloc[ind-1]['labels'])]\n",
    "                users[email]['labels']=lab\n",
    "            else:\n",
    "                users[email]['news'].append(df_temp.iloc[ind-1]['Source']+df_temp.iloc[ind-1]['Date']+ast.literal_eval(df_temp.iloc[ind-1]['Titles'])[0])\n",
    "                lab=[z for z in ast.literal_eval(df_temp.iloc[ind-1]['labels'])]\n",
    "                for l in lab:\n",
    "                    users[email]['labels'].append(l)\n",
    "            with open(\"user_records.json\", \"w\") as outfile: \n",
    "                json.dump(users, outfile)\n",
    "\n",
    "            file_s = open('story_records.json')\n",
    "            stories=json.load(file_s)\n",
    "            key=df_temp.iloc[ind-1]['Source']+df_temp.iloc[ind-1]['Date']+ast.literal_eval(df_temp.iloc[ind-1]['Titles'])[0]\n",
    "\n",
    "            if key not in stories.keys():\n",
    "\n",
    "                stories[key]=[email]\n",
    "            else:\n",
    "                stories[key].append(email)\n",
    "\n",
    "            with open(\"story_records.json\", \"w\") as outfile: \n",
    "                json.dump(stories, outfile) \n",
    "        except:\n",
    "            a=1\n",
    "        handle_similar(df,ast.literal_eval(df_temp.iloc[ind-1]['Titles'])[0],email)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(email,df):\n",
    "    clear()\n",
    "    search=input(\"search\")\n",
    "    df_temp=df\n",
    "    sim=[]\n",
    "    for i in range(len(df)):\n",
    "        try:\n",
    "            title=ast.literal_eval(df.iloc[i]['Titles'])[0]\n",
    "            cleaned_1=clean_sentence(search)\n",
    "            cleaned_2=clean_sentence(title)\n",
    "            stop_words = stopwords.words('english')\n",
    "            s=get_similarity(cleaned_1,cleaned_2,stop_words)\n",
    "            if s<0.95:\n",
    "                sim.append(s)\n",
    "            else:\n",
    "                sim.append(0)\n",
    "        except:\n",
    "            sim.append(0)\n",
    "            \n",
    "    df_temp['Sim']=sim\n",
    "    df_temp.sort_values(by=['Sim'], inplace=True,ascending=False)\n",
    "    #print(df_temp.head())\n",
    "    print(\"\\n\\n Top 5 Results \\n\")\n",
    "    for i in range(5):\n",
    "        \n",
    "            res = ast.literal_eval(df_temp.iloc[i]['Titles']) \n",
    "            print(str(i+1)+\"-> \"+res[0])\n",
    "            print(df_temp.iloc[i]['Source']+\" , \"+df_temp.iloc[i]['Date'])\n",
    "        \n",
    "            print('\\n\\n')\n",
    "        \n",
    "    ind=int(input(\"Please Provide the index of the story\"))\n",
    "        #print(str(stories_checked.iloc[indices[ind-1]]['link']))\n",
    "    \n",
    "            #ind=int(input(\"Please Provide the index of the story\"))\n",
    "    webbrowser.open(df_temp.iloc[ind-1]['link'])\n",
    "    time.sleep(3)\n",
    "    \n",
    "    try:\n",
    "    \n",
    "            file_u = open('user_records.json')\n",
    "            users=json.load(file_u)\n",
    "\n",
    "            if email not in users.keys():\n",
    "                users[email]={}\n",
    "                \n",
    "                users[email]['news']=[df_temp[ind-1]['Source']+df_temp.iloc[ind-1]['Date']+ast.literal_eval(df_temp.iloc[ind-1]['Titles'])[0]]\n",
    "                lab=[z for z in ast.literal_eval(df_temp.iloc[ind-1]['labels'])]\n",
    "                users[email]['labels']=lab\n",
    "            else:\n",
    "                users[email]['news'].append(df_temp.iloc[ind-1]['Source']+df_temp.iloc[ind-1]['Date']+ast.literal_eval(df_temp.iloc[ind-1]['Titles'])[0])\n",
    "                lab=[z for z in ast.literal_eval(df_temp.iloc[ind-1]['labels'])]\n",
    "                for l in lab:\n",
    "                    users[email]['labels'].append(l)\n",
    "        \n",
    "            with open(\"user_records.json\", \"w\") as outfile: \n",
    "                json.dump(users, outfile)\n",
    "    \n",
    "            file_s = open('story_records.json')\n",
    "            stories=json.load(file_s)\n",
    "            key=df_temp.iloc[ind-1]['Source']+df_temp.iloc[ind-1]['Date']+ast.literal_eval(df_temp.iloc[ind-1]['Titles'])[0]\n",
    "\n",
    "            if key not in stories.keys():\n",
    "\n",
    "                stories[key]=[email]\n",
    "            else:\n",
    "                stories[key].append(email)\n",
    "\n",
    "            with open(\"story_records.json\", \"w\") as outfile: \n",
    "                json.dump(stories, outfile) \n",
    "    except:\n",
    "    \n",
    "            a=1\n",
    "    surf(email)\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def get_popular(email,df):\n",
    "    clear()\n",
    "    #print(\"A\")\n",
    "    df_temp=df\n",
    "    file_u = open('user_records.json')\n",
    "    users=json.load(file_u)\n",
    "    file_s = open('story_records.json')\n",
    "    stories=json.load(file_s)\n",
    "    \n",
    "    popularity=[]\n",
    "    for i in range(len(df)):\n",
    "        try:\n",
    "            key=df.iloc[i]['Source']+'$'+df.iloc[i]['Date']+'$'+ast.literal_eval(df_temp.iloc[i]['Titles'])[0]\n",
    "            if key in stories.keys():\n",
    "                p=stories.get(key)\n",
    "                if email in p:\n",
    "                    popularity.append(0)\n",
    "                else:\n",
    "                    popularity.append(len(p))\n",
    "            else:\n",
    "                popularity.append(0)\n",
    "        except:\n",
    "            popularity.append(0)\n",
    "    \n",
    "    df_temp['Pop']=popularity \n",
    "    df_temp.sort_values(by=['Pop'], inplace=True,ascending=False)\n",
    "    print(\"\\n\\n Top 10 Results \\n\")\n",
    "    for i in range(10):\n",
    "        try:\n",
    "            res = ast.literal_eval(df_temp.iloc[i]['Titles']) \n",
    "            print(str(i+1)+\"-> \"+res[0])\n",
    "            print(df_temp.iloc[i]['Source']+\" , \"+df_temp.iloc[i]['Date'])\n",
    "        \n",
    "            print('\\n\\n')\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "    ind=int(input(\"Please Provide the index of the story\"))\n",
    "        #print(str(stories_checked.iloc[indices[ind-1]]['link']))\n",
    "    \n",
    "            #ind=int(input(\"Please Provide the index of the story\"))\n",
    "    webbrowser.open(df_temp.iloc[ind-1]['link'])\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "            file_u = open('user_records.json')\n",
    "            users=json.load(file_u)\n",
    "\n",
    "            if email not in users.keys():\n",
    "                users[email]={}\n",
    "                \n",
    "                users[email]['news']=[df_temp[ind-1]['Source']+df_temp.iloc[ind-1]['Date']+ast.literal_eval(df_temp.iloc[ind-1]['Titles'])[0]]\n",
    "                lab=[z for z in ast.literal_eval(df_temp.iloc[ind-1]['labels'])]\n",
    "                users[email]['labels']=lab\n",
    "            else:\n",
    "                users[email]['news'].append(df_temp.iloc[ind-1]['Source']+df_temp.iloc[ind-1]['Date']+ast.literal_eval(df_temp.iloc[ind-1]['Titles'])[0])\n",
    "                lab=[z for z in ast.literal_eval(df_temp.iloc[ind-1]['labels'])]\n",
    "                for l in lab:\n",
    "                    users[email]['labels'].append(l)\n",
    "                \n",
    "            with open(\"user_records.json\", \"w\") as outfile: \n",
    "                json.dump(users, outfile)\n",
    "\n",
    "            file_s = open('story_records.json')\n",
    "            stories=json.load(file_s)\n",
    "            key=df_temp.iloc[ind-1]['Source']+df_temp.iloc[ind-1]['Date']+ast.literal_eval(df_temp.iloc[ind-1]['Titles'])[0]\n",
    "\n",
    "            if key not in stories.keys():\n",
    "\n",
    "                stories[key]=[email]\n",
    "            else:\n",
    "                stories[key].append(email)\n",
    "\n",
    "            with open(\"story_records.json\", \"w\") as outfile: \n",
    "                json.dump(stories, outfile) \n",
    "    except:\n",
    "            a=1\n",
    "    surf(email)\n",
    "\n",
    "    \n",
    "    \n",
    "            \n",
    "        \n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content Based Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def get_customized(email,df):\n",
    "    clear()\n",
    "    file_u = open('user_records.json')\n",
    "    users=json.load(file_u)\n",
    "    \n",
    "    file_s = open('story_records.json')\n",
    "    stories=json.load(file_s)\n",
    "        \n",
    "    df_temp=df\n",
    "    \n",
    "    sim=[]\n",
    "    \n",
    "    if email in users.keys():\n",
    "        tag_usr=\"\"\n",
    "        temp=users.get(email)\n",
    "        temp=temp.get('labels')\n",
    "        i= len(temp)-1\n",
    "        count=0\n",
    "        while i>=0:\n",
    "            if count==20:\n",
    "                break\n",
    "            tag_usr+=temp[i]+\" \"\n",
    "            i-=1\n",
    "            count+=1\n",
    "        #print(tag_usr)\n",
    "        for i in range(len(df)):\n",
    "            try:\n",
    "                key=df.iloc[i]['Source']+'$'+df.iloc[i]['Date']+'$'+ast.literal_eval(df_temp.iloc[i]['Titles'])[0]\n",
    "                if key in stories.keys():\n",
    "                    p=stories.get(key)\n",
    "                    if email in p:\n",
    "                        sim.append(0)\n",
    "                    else:\n",
    "                        tag_str=\"\"\n",
    "                        lab=ast.literal_eval(df_temp.iloc[i][\"labels\"])\n",
    "                        for l in lab:\n",
    "                            tag_str+=l+\" \"\n",
    "                        cleaned_1=clean_sentence(tag_usr)\n",
    "                        cleaned_2=clean_sentence(tag_str)\n",
    "                        s=get_similarity(cleaned_1,cleaned_2)\n",
    "                        sim.append(s)\n",
    "                        \n",
    "                        \n",
    "                else:\n",
    "                    sim.append(0)\n",
    "            except:\n",
    "                sim.append(0)\n",
    "        df_temp['sim']=sim \n",
    "        df_temp.sort_values(by=['sim'], inplace=True,ascending=False)\n",
    "        print(\"\\n\\n Top 10 Results \\n\")\n",
    "        for i in range(10):\n",
    "            try:\n",
    "                res = ast.literal_eval(df_temp.iloc[i]['Titles']) \n",
    "                print(str(i+1)+\"-> \"+res[0])\n",
    "                print(df_temp.iloc[i]['Source']+\" , \"+df_temp.iloc[i]['Date'])\n",
    "        \n",
    "                print('\\n\\n')\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        ind=int(input(\"Please Provide the index of the story\"))\n",
    "            #print(str(stories_checked.iloc[indices[ind-1]]['link']))\n",
    "    \n",
    "            #ind=int(input(\"Please Provide the index of the story\"))\n",
    "        webbrowser.open(df_temp.iloc[ind-1]['link'])\n",
    "        time.sleep(3)\n",
    "        try:\n",
    "                file_u = open('user_records.json')\n",
    "                users=json.load(file_u)\n",
    "\n",
    "                if email not in users.keys():\n",
    "                    users[email]={}\n",
    "                \n",
    "                    users[email]['news']=[df_temp[ind-1]['Source']+df_temp.iloc[ind-1]['Date']+ast.literal_eval(df_temp.iloc[ind-1]['Titles'])[0]]\n",
    "                    lab=[z for z in ast.literal_eval(df_temp.iloc[ind-1]['labels'])]\n",
    "                    users[email]['labels']=lab\n",
    "                else:\n",
    "                    users[email]['news'].append(df_temp.iloc[ind-1]['Source']+df_temp.iloc[ind-1]['Date']+ast.literal_eval(df_temp.iloc[ind-1]['Titles'])[0])\n",
    "                    lab=[z for z in ast.literal_eval(df_temp.iloc[ind-1]['labels'])]\n",
    "                    for l in lab:\n",
    "                        users[email]['labels'].append(l)\n",
    "                \n",
    "                with open(\"user_records.json\", \"w\") as outfile: \n",
    "                    json.dump(users, outfile)\n",
    "\n",
    "                file_s = open('story_records.json')\n",
    "                stories=json.load(file_s)\n",
    "                key=df_temp.iloc[ind-1]['Source']+df_temp.iloc[ind-1]['Date']+ast.literal_eval(df_temp.iloc[ind-1]['Titles'])[0]\n",
    "\n",
    "                if key not in stories.keys():\n",
    "\n",
    "                    stories[key]=[email]\n",
    "                else:\n",
    "                    stories[key].append(email)\n",
    "\n",
    "                with open(\"story_records.json\", \"w\") as outfile: \n",
    "                    json.dump(stories, outfile) \n",
    "        except:\n",
    "                a=1\n",
    "        handle_similar(df,ast.literal_eval(df_temp.iloc[ind-1]['Titles'])[0],email)\n",
    "         \n",
    "    else:\n",
    "        get_popular(email,df)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime \n",
    "import random\n",
    "import ast,time\n",
    "import webbrowser\n",
    "import json\n",
    "def surf(email):\n",
    "    clear()\n",
    "    date=datetime.today().strftime('%Y-%m-%d')\n",
    "    \n",
    "    stories=get_stories()\n",
    "    \n",
    "    stories_checked=stories[stories[\"Date\"]==date]\n",
    "    length=len(stories_checked)\n",
    "    print()\n",
    "    indices=[]\n",
    "    \n",
    "    for _ in range(8):\n",
    "        indices.append(random.randint(0,length))\n",
    "    \n",
    "    print(\"LATEST FEED: \\n\\n\")\n",
    "    \n",
    "    for i in range(len(indices)-1):\n",
    "        try:\n",
    "            #print(indices[i])\n",
    "            res = ast.literal_eval(stories_checked.iloc[indices[i]]['Titles']) \n",
    "            print(str(i+1)+\"-> \"+res[0])\n",
    "            print(stories_checked.iloc[indices[i]]['Source']+\", Today\")\n",
    "        \n",
    "            print('\\n\\n')\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "    print('1 for searching, 2 for reading from feed, 3 for popular stories, 4 for customized stories, 5 to quit')\n",
    "    \n",
    "    choice=int(input())\n",
    "    if choice==2:\n",
    "        \n",
    "            ind=int(input(\"Please Provide the index of the story\"))\n",
    "            #print(str(stories_checked.iloc[indices[ind-1]]['link']))\n",
    "            webbrowser.open(str(stories_checked.iloc[indices[ind-1]]['link']))\n",
    "            time.sleep(3)\n",
    "        \n",
    "            file_u = open('user_records.json')\n",
    "            users=json.load(file_u)\n",
    "\n",
    "            if email not in users.keys():\n",
    "                users[email]={}\n",
    "                \n",
    "                users[email]['news']=[stories_checked.iloc[indices[ind-1]]['Source']+stories_checked.iloc[indices[ind-1]]['Date']+ast.literal_eval(stories_checked.iloc[indices[ind-1]]['Titles'])[0]]\n",
    "                lab=[z for z in ast.literal_eval(stories_checked.iloc[indices[ind-1]]['labels'])]\n",
    "                users[email]['labels']=lab\n",
    "            else:\n",
    "                users[email]['news'].append(stories_checked.iloc[indices[ind-1]]['Source']+stories_checked.iloc[indices[ind-1]]['Date']+ast.literal_eval(stories_checked.iloc[indices[ind-1]]['Titles'])[0])\n",
    "                lab=[z for z in ast.literal_eval(stories_checked.iloc[indices[ind-1]]['labels'])]\n",
    "                for l in lab:\n",
    "                    users[email]['labels'].append(l)\n",
    "            #json.dump(users,'user_records.json')\n",
    "            #print(users)\n",
    "            \n",
    "            with open(\"user_records.json\", \"w\") as outfile: \n",
    "                json.dump(users, outfile) \n",
    "\n",
    "            file_s = open('story_records.json')\n",
    "            stories=json.load(file_s)\n",
    "            key=stories_checked.iloc[indices[ind-1]]['Source']+'$'+stories_checked.iloc[indices[ind-1]]['Date']+'$'+ast.literal_eval(stories_checked.iloc[indices[ind-1]]['Titles'])[0]\n",
    "\n",
    "            if key not in stories.keys():\n",
    "\n",
    "                stories[key]=[email]\n",
    "            else:\n",
    "                stories[key].append(email)\n",
    "            with open(\"story_records.json\", \"w\") as outfile: \n",
    "                json.dump(stories, outfile) \n",
    "\n",
    "            a=1\n",
    "        #json.dump(stories,'story_records.json')\n",
    "        \n",
    "        \n",
    "            handle_similar(stories_checked,ast.literal_eval(stories_checked.iloc[indices[ind-1]]['Titles'])[0],email)\n",
    "    elif choice==1:\n",
    "        search(email,stories)\n",
    "    \n",
    "    elif choice==3:\n",
    "        get_popular(email,stories)\n",
    "    \n",
    "    elif choice==4:\n",
    "        get_customized(email,stories)\n",
    "        \n",
    "    elif choice==5:\n",
    "        print(\"BYE\")\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 to Signup, 2 to Login\n",
      "2\n",
      "Email:XYZ@gmail.com\n",
      "Pass:1234\n",
      "Welcome XYZ\n",
      "\n",
      "LATEST FEED: \n",
      "\n",
      "\n",
      "1-> With single-day spike of 75,809 cases and record 1,133 deaths, India's COVID-19 tally nears 43 lakh mark\n",
      "Times_Now, Today\n",
      "\n",
      "\n",
      "\n",
      "2->  Sikhs to be counted as a separate ethnic group in 2020 US census for first time\n",
      "IndiaToday, Today\n",
      "\n",
      "\n",
      "\n",
      "3->  IMPACT FEATURE Campus placements go virtual as universities adapt\n",
      "IndiaToday, Today\n",
      "\n",
      "\n",
      "\n",
      "4-> Delhi BJP Stages Protest, Says AAP Govt Should Release Funds Of Municipal Corporations\n",
      "Republic TV, Today\n",
      "\n",
      "\n",
      "\n",
      "5-> Kerala gold smuggling case: Swapna Suresh shifted to ICU after complaining of chest pain\n",
      "Times_Now, Today\n",
      "\n",
      "\n",
      "\n",
      "6->  Govt orders clinical study into Covid-19 re-infection after Bengaluru case\n",
      "IndiaToday, Today\n",
      "\n",
      "\n",
      "\n",
      "7-> Subramanian Swamy Questions EAM Jaishankar's Scheduled Meeting With Chinese FM In Moscow\n",
      "Republic TV, Today\n",
      "\n",
      "\n",
      "\n",
      "1 for searching, 2 for reading from feed, 3 for popular stories, 4 for customized stories, 5 to quit\n",
      "2\n",
      "Please Provide the index of the story4\n",
      "\n",
      "\n",
      " Here are some similar Stories \n",
      "\n",
      "\n",
      "1-> MS Dhoni leaves Irfan Pathan surprised, does wicket-keeping drills in CSK training ahead of IPL 2020\n",
      "Times_Now, Today\n",
      "\n",
      "\n",
      "\n",
      "2-> COVID-19 Menace Can Only Be Tackled With Active Support Of People: Rajasthan Health Minister\n",
      "Republic TV, Today\n",
      "\n",
      "\n",
      "\n",
      "3->     Sushant Singh Rajput case LIVE updates: NCB summons Rhea 3rd time\n",
      "IndiaToday, Today\n",
      "\n",
      "\n",
      "\n",
      "4-> BJP and Shiv Sena lock horns over election of deputy chairman\n",
      "Times_Now, Today\n",
      "\n",
      "\n",
      "\n",
      "5-> Mumbai PoK row: Shiv Sena IT cell files complaint against Kangana Ranaut seeking FIR under sedition charge\n",
      "Times_Now, Today\n",
      "\n",
      "\n",
      "\n",
      "1 for choosing proposed, 2 to go back\n",
      "2\n",
      "\n",
      "LATEST FEED: \n",
      "\n",
      "\n",
      "1-> 6 Workers Fall Sick After Gas Leak From Factory In Maharashtra\n",
      "Republic TV, Today\n",
      "\n",
      "\n",
      "\n",
      "2-> First batch of Russian coronavirus vaccine released into public\n",
      "Times_Now, Today\n",
      "\n",
      "\n",
      "\n",
      "3-> Delhi BJP Stages Protest, Says AAP Govt Should Release Funds Of Municipal Corporations\n",
      "Republic TV, Today\n",
      "\n",
      "\n",
      "\n",
      "4-> No firing happened: India denies Chinese claims of 'fired threats' by Indian Army troops south of Pangong Tso\n",
      "Times_Now, Today\n",
      "\n",
      "\n",
      "\n",
      "5-> Kamala Harris will never be president, says Trump, slams Democrats’ for ‘reckless anti-vaccine rhetoric’\n",
      "Times_Now, Today\n",
      "\n",
      "\n",
      "\n",
      "6-> Controlled, Not Crushed: Jaish-e-Muhammad Asks Pakistan to Lift Restrictions on Attacks in Kashmir\n",
      "News18, Today\n",
      "\n",
      "\n",
      "\n",
      "7-> China acted in an open and transparent manner on coronavirus outbreak, says President Xi Jinping\n",
      "Times_Now, Today\n",
      "\n",
      "\n",
      "\n",
      "1 for searching, 2 for reading from feed, 3 for popular stories, 4 for customized stories, 5 to quit\n",
      "5\n",
      "BYE\n"
     ]
    }
   ],
   "source": [
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
